# Use a local LLM to question your sensitive data

This is a small demo to write a python code that interacts with a local database and LLM.

The database is simulated with a simple json file.

The LLM is smolLLM v2 running in a Docker container pulled from Docker Desktop

Don't forget to evable Docker Model Runner and host-side TCP support in the Beta Features settings. 

![Demo Thumbnail](data/yt_thumbnail.png)